{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create a model used to predict whether the individual patient has an allergy\n",
    "# Use different notebook to load the model and return a prediction\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "# Import both datasets, change to local path when running\n",
    "patients = pd.read_excel(r\"C:\\Users\\me\\OneDrive\\Desktop\\Senior Design\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level2_AI_Patient Traits\")\n",
    "\n",
    "allergies = pd.read_excel(r\"C:\\Users\\me\\OneDrive\\Desktop\\Senior Design\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level1_Patient Allergens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that patient sheet imported correctly\n",
    "# Comment below line before committing\n",
    "# patients['SkinConditions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34eed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm allergy sheet imported correctly\n",
    "# Comment line before committing\n",
    "# allergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb333603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge columns by ID if needed\n",
    "patientAllergies = patients.merge(allergies, on = \"SFM Id\")\n",
    "# Comment line before committing\n",
    "# patientAllergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c97a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID and location columns from dataframe\n",
    "patientsTrimmed = patients.drop(['SFM Id', 'City', 'State', 'Country'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecc338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode Gender column\n",
    "patientsTrimmed['Gender'] = pd.Categorical(patientsTrimmed['Gender'].str.strip())\n",
    "gender_onehot = pd.get_dummies(patientsTrimmed['Gender'], prefix = \"Gender\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('Gender', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(gender_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50d9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode SkinTone column\n",
    "patientsTrimmed['SkinTone'] = pd.Categorical(patientsTrimmed['SkinTone'].str.strip())\n",
    "skintone_onehot = pd.get_dummies(patientsTrimmed['SkinTone'], prefix = \"SkinTone\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinTone', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(skintone_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fc1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode FitzPatrickSkinPhotoType column\n",
    "patientsTrimmed['FitzpatrickSkinPhotoType'] = pd.Categorical(patientsTrimmed['FitzpatrickSkinPhotoType'].str.strip())\n",
    "# Dropping first here since it is a blank variable in the column\n",
    "fitzpatrick_onehot = pd.get_dummies(patientsTrimmed['FitzpatrickSkinPhotoType'], prefix = \"Fitzpatrick\",\n",
    "                                    prefix_sep = \"-\", drop_first = True, dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('FitzpatrickSkinPhotoType', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(fitzpatrick_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c818e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching to TextVectorization (Tokenizer is deprecated)\n",
    "from keras.layers import TextVectorization\n",
    "# Replace commas with whitespace\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].str.replace(',', ' ')\n",
    "# Set the max length based on whitespace characters\n",
    "max_len = patientsTrimmed['SkinConditions'].str.count(' ').max()\n",
    "# Create TextVectorization object, separating on whitespace and using the max_len from earlier\n",
    "vectorizer = TextVectorization(split = 'whitespace', output_sequence_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt using the column we want to convert\n",
    "vectorizer.adapt(patientsTrimmed['SkinConditions'].values)\n",
    "# Reset the column after converting values to vector and placing in array\n",
    "skinConditions = vectorizer(patientsTrimmed['SkinConditions']).numpy()\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinConditions', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5781a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsArr = patientsTrimmed.values\n",
    "input_data = np.concatenate((patientsArr, skinConditions), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Old code for SkinConditions conversion - leaving in case we need later\n",
    "# Code to preprocess the SkinConditions column, tokenizing should be more recognizable to keras than regular text\n",
    "## Delete if this idea does not work\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten entries into actual lists\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].apply(lambda x: ' '.join(x))\n",
    "# Tokenize the characters of the columns\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(patientsTrimmed['SkinConditions'])\n",
    "# Create and pad sequences of the tokens\n",
    "patientsTrimmed['SkinConditions'] = tokenizer.texts_to_sequences(patientsTrimmed['SkinConditions'])\n",
    "max_length = max(len(seq) for seq in patientsTrimmed['SkinConditions'])\n",
    "testVar = pad_sequences(patientsTrimmed['SkinConditions'], maxlen = max_length, padding = \"post\")\n",
    "patientsTrimmed['SkinConditions'] = testVar.tolist()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a785a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column for preprocessing - ID should have no effect on prediction\n",
    "allergiesNoId = allergies.drop('SFM Id', axis = 1)\n",
    "# Remove all non-digit characters, then replace empty cells with NaN\n",
    "allergiesNoId = allergiesNoId.replace(r'\\D+', '', regex = True).replace('', np.nan)\n",
    "# Set all NaN cells to 0\n",
    "allergiesNoId = allergiesNoId.fillna(0)\n",
    "# Convert entire dataframe to integer\n",
    "allergiesNoId = allergiesNoId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f83d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNoId['AllergiesList'] = allergiesNoId.astype(str).apply(' '.join, axis=1)\n",
    "allergiesNoId['AllergiesList'] = allergiesNoId['AllergiesList'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a60a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Create MultiLabelBinarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "allergiesArr = np.array(allergiesNoId['AllergiesList'])\n",
    "# Multi-hot encode data\n",
    "allergiesArray = mlb.fit_transform(allergiesArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9568019",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNew = mlb.inverse_transform(allergiesArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac504b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesDF = pd.DataFrame(mlb.transform(allergiesArr), columns = mlb.classes_)\n",
    "allergiesDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b032100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold #:  1\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0092 - val_loss: 0.0050\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0073 - val_loss: 0.0084\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0118\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0086\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0068\n",
      "62/62 [==============================] - 0s 934us/step\n",
      "X values for test:  [1950    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    3    5    2    6    4    8    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '124', '144962', '1462', '1590', '1600', '1607', '1827', '188', '5468', '5986', '9300')\n",
      "Predicted values as list:  ('0', '103637', '105017', '10541', '1149', '1153', '11996', '124', '12522', '13018', '132762', '134800', '136', '13891', '1453', '148092', '149879', '1586', '1589', '1590', '1594', '1601', '1604', '1605', '1607', '1613', '1826', '1827', '185', '1903', '193', '1995', '1997', '201', '2023', '204', '2042', '21340', '227', '2306', '2383', '28559', '28772', '322', '3222', '33172', '3793', '38080', '3962', '4550', '459', '4617', '4929', '5236', '5272', '5345', '5405', '5467', '5538', '5926', '607', '6096', '614', '62', '6416', '68258', '68271', '7086', '73771', '800', '8379', '83935', '8469', '9277', '9300', '9308', '9314', '9315', '9338', '9344', '94128', '95438')\n",
      "[1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0.3488372\n",
      "0.05952821\n",
      "0.6446342\n",
      "0.2288552\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  2\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0065 - val_loss: 0.0033\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0087\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0067\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0088\n",
      "62/62 [==============================] - 0s 803us/step\n",
      "X values for test:  [2000    0    1    0    0    0    1    0    0    0    0    0    0    0\n",
      "    0    0    0   14    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '15438', '18419', '5443')\n",
      "Predicted values as list:  ('0', '1153', '11661', '12344', '12522', '131997', '132762', '136', '139053', '144962', '151560', '1586', '1588', '1589', '1590', '1596', '1598', '1604', '1605', '1607', '1609', '1610', '1611', '1613', '1802', '1826', '1827', '1893', '190', '1903', '196', '1997', '201', '2023', '204', '2042', '210', '227', '23250', '240', '24061', '25159', '257', '26137', '263', '28559', '33173', '3793', '38080', '41508', '41609', '4550', '459', '4619', '51508', '5248', '5272', '5405', '5468', '5986', '607', '615', '61707', '62', '6509', '6841', '69227', '7086', '7431', '7578', '800', '8140', '8376', '9310', '9314', '9315', '9335', '9341', '9358', '95438')\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3508892\n",
      "0.05852904\n",
      "0.62238187\n",
      "0.2264099\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   3    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]]\n",
      "Running fold #:  3\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0097\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.0056\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0069\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0121 - val_loss: 0.0085\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0089 - val_loss: 0.0103\n",
      "62/62 [==============================] - 0s 918us/step\n",
      "X values for test:  [1946    1    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "    0    0    0    3    7    2    6    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '1600', '1613', '201', '2023', '2787', '9315', '9456')\n",
      "Predicted values as list:  ('0', '103637', '10537', '11661', '124', '12522', '130118', '134800', '144962', '1589', '159', '1601', '1604', '1605', '1609', '1610', '1611', '1802', '1827', '183', '188', '1893', '1903', '1964', '201', '204', '2269', '227', '23454', '23944', '240', '263', '28559', '3127', '33172', '33173', '3793', '38080', '41609', '41989', '4550', '459', '4617', '4701', '4824', '51508', '5236', '5248', '5272', '5467', '5986', '607', '614', '615', '61707', '6416', '6509', '7086', '73771', '7737', '83935', '8469', '8512', '9275', '9276', '9298', '9300', '9308', '9310', '9314', '9337', '9338', '9358', '9392')\n",
      "[1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0.3248974\n",
      "0.060490035\n",
      "0.6017381\n",
      "0.22662407\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  4\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0056 - val_loss: 0.0027\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0080\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "62/62 [==============================] - 0s 1ms/step\n",
      "X values for test:  [1985    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    3    7    5    2    4    8    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '12522', '1598', '1605', '1805', '201', '2023', '215', '2350', '257', '263', '3799', '5236', '5467', '9315')\n",
      "Predicted values as list:  ('0', '103637', '10541', '1149', '124', '12522', '130118', '131996', '132762', '134800', '144962', '148092', '151557', '1588', '1592', '1595', '1598', '1601', '1602', '1605', '1607', '1610', '1827', '1964', '1997', '2023', '2042', '2047', '2053', '2269', '227', '24061', '263', '28559', '2908', '33173', '3793', '3799', '41609', '41728', '41989', '4550', '459', '5236', '5405', '5467', '607', '6096', '613', '6416', '6509', '68', '7086', '7431', '800', '8140', '83935', '9274', '9277', '9308', '9312', '9314', '9338', '9342', '9344', '95426', '95438')\n",
      "[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34336525\n",
      "0.064747006\n",
      "0.5976747\n",
      "0.22157457\n",
      "[[[   0    0]\n",
      "  [   0 1979]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1976    0]\n",
      "  [   3    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  5\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0039\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0090\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0114\n",
      "62/62 [==============================] - 0s 951us/step\n",
      "X values for test:  [1942    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    7    2    4    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '1600', '1607', '2013', '2023', '2046', '26137', '614', '9375')\n",
      "Predicted values as list:  ('0', '10541', '1107', '1149', '1153', '11996', '121146', '124737', '12522', '13018', '131996', '134800', '144962', '148092', '1586', '1588', '1589', '1590', '1594', '1597', '1598', '1600', '1601', '1604', '1609', '1610', '1827', '183', '184', '196', '1995', '1997', '2020', '2023', '203', '227', '2270', '23944', '24061', '257', '263', '28559', '33172', '33173', '3793', '3799', '38080', '418', '44465', '459', '51508', '5248', '5272', '5405', '6020', '607', '6096', '613', '61707', '6509', '7086', '7737', '799', '800', '839', '8469', '9116', '9276', '9277', '9300', '9308', '9310', '9312', '9314', '9315', '9337', '9341', '9342', '9344', '95438', '96771')\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "0.35430917\n",
      "0.05497851\n",
      "0.5937079\n",
      "0.20343184\n",
      "[[[   0    0]\n",
      "  [   0 1979]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "from keras.layers import Average\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7869)\n",
    "\n",
    "#weight_array = compute_class_weight(class_weight = 'balanced', \n",
    "                                    #classes = np.unique(np.argmax(allergiesArray, axis=1)), \n",
    "                                    #y = np.argmax(allergiesArray, axis=1))\n",
    "#print(weight_array)\n",
    "#weight_dict = dict(zip(np.unique(np.argmax(allergiesArray, axis=1)), weight_array))\n",
    "#print(weight_dict)\n",
    "\n",
    "fold_count = 1\n",
    "# Train the model for each split\n",
    "# Define the model inside the for loop\n",
    "for train, test in cv.split(input_data,allergiesArray):\n",
    "\n",
    "    n_classes = 731\n",
    "\n",
    "    # Input layer\n",
    "    input_shape = (40,)\n",
    "    inputs = keras.Input(input_shape)\n",
    "\n",
    "    # Hidden layers\n",
    "    x = Dense(128, activation='sigmoid')(inputs)\n",
    "    x = Dense(512, activation = 'sigmoid')(x)\n",
    "\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions = Dense(n_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = predictions)\n",
    "    model.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha = 0.05, gamma = 10), optimizer=keras.optimizers.Adam(learning_rate=0.1))\n",
    "    \n",
    "    print(\"Running fold #: \", fold_count)\n",
    "\n",
    "    fold_train_x =input_data[train]\n",
    "    \n",
    "    history = model.fit(\n",
    "    fold_train_x, allergiesArray[train],\n",
    "    epochs = 20, \n",
    "    verbose = 1, \n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "    fold_test_x = input_data[test]\n",
    "    y_true = allergiesArray[test]\n",
    "    \n",
    "    # pred_y = model.predict_classes(fold_test_x, verbose = 1)\n",
    "    probs = model.predict(fold_test_x, verbose = 1)\n",
    "    \n",
    "\n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\\\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    threshold = 0.35\n",
    "    probs = (probs > threshold).astype(int)\n",
    "    # print(\"Predicted y values: \", pred_y[0])\n",
    "    print(\"X values for test: \", fold_test_x[0])\n",
    "    yList = mlb.inverse_transform(y_true)\n",
    "    print(\"Actual y values as list: \", yList[0])\n",
    "    probsList = mlb.inverse_transform(probs)\n",
    "    print(\"Predicted values as list: \", probsList[0])\n",
    "    print(probs[0])\n",
    "    \n",
    "    auc.update_state(y_true, probs)\n",
    "    print(auc.result().numpy())\n",
    "    prec.update_state(y_true, probs)\n",
    "    print(prec.result().numpy())\n",
    "    rec.update_state(y_true, probs)\n",
    "    print(rec.result().numpy())\n",
    "    f1.update_state(y_true, probs)\n",
    "    print(f1.result().numpy())\n",
    "    \n",
    "    matrix = multilabel_confusion_matrix(y_true, probs)\n",
    "    print(matrix)\n",
    "    \n",
    "    # print(\"Accuracy score sklearn: \", accuracy_score(allergiesArray[test], probs))\n",
    "    accuracy = (allergiesArray[test] == probs).all(axis=(0,1)).mean()\n",
    "    # print(\"Accuracy score equation: \", accuracy)\n",
    "\n",
    "    fold_count = fold_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save Keras model as separate file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
