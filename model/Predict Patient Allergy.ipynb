{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create a model used to predict whether the individual patient has an allergy\n",
    "# Use different notebook to load the model and return a prediction\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "# Import both datasets, change to local path when running\n",
    "patients = pd.read_excel(r\"C:\\Users\\me\\OneDrive\\Desktop\\Senior Design\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level2_AI_Patient Traits\")\n",
    "\n",
    "allergies = pd.read_excel(r\"C:\\Users\\me\\OneDrive\\Desktop\\Senior Design\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level1_Patient Allergens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that patient sheet imported correctly\n",
    "# Comment below line before committing\n",
    "# patients['SkinConditions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34eed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm allergy sheet imported correctly\n",
    "# Comment line before committing\n",
    "# allergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb333603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge columns by ID if needed\n",
    "patientAllergies = patients.merge(allergies, on = \"SFM Id\")\n",
    "# Comment line before committing\n",
    "# patientAllergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c97a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID and location columns from dataframe\n",
    "patientsTrimmed = patients.drop(['SFM Id', 'City', 'State', 'Country'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecc338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode Gender column\n",
    "patientsTrimmed['Gender'] = pd.Categorical(patientsTrimmed['Gender'].str.strip())\n",
    "gender_onehot = pd.get_dummies(patientsTrimmed['Gender'], prefix = \"Gender\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('Gender', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(gender_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50d9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode SkinTone column\n",
    "patientsTrimmed['SkinTone'] = pd.Categorical(patientsTrimmed['SkinTone'].str.strip())\n",
    "skintone_onehot = pd.get_dummies(patientsTrimmed['SkinTone'], prefix = \"SkinTone\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinTone', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(skintone_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fc1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode FitzPatrickSkinPhotoType column\n",
    "patientsTrimmed['FitzpatrickSkinPhotoType'] = pd.Categorical(patientsTrimmed['FitzpatrickSkinPhotoType'].str.strip())\n",
    "# Dropping first here since it is a blank variable in the column\n",
    "fitzpatrick_onehot = pd.get_dummies(patientsTrimmed['FitzpatrickSkinPhotoType'], prefix = \"Fitzpatrick\",\n",
    "                                    prefix_sep = \"-\", drop_first = True, dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('FitzpatrickSkinPhotoType', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(fitzpatrick_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c818e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching to TextVectorization (Tokenizer is deprecated)\n",
    "from keras.layers import TextVectorization\n",
    "# Replace commas with whitespace\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].str.replace(',', ' ')\n",
    "# Set the max length based on whitespace characters\n",
    "max_len = patientsTrimmed['SkinConditions'].str.count(' ').max()\n",
    "# Create TextVectorization object, separating on whitespace and using the max_len from earlier\n",
    "vectorizer = TextVectorization(split = 'whitespace', output_sequence_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt using the column we want to convert\n",
    "vectorizer.adapt(patientsTrimmed['SkinConditions'].values)\n",
    "# Reset the column after converting values to vector and placing in array\n",
    "skinConditions = vectorizer(patientsTrimmed['SkinConditions']).numpy()\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinConditions', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5781a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsArr = patientsTrimmed.values\n",
    "input_data = np.concatenate((patientsArr, skinConditions), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Old code for SkinConditions conversion - leaving in case we need later\n",
    "# Code to preprocess the SkinConditions column, tokenizing should be more recognizable to keras than regular text\n",
    "## Delete if this idea does not work\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten entries into actual lists\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].apply(lambda x: ' '.join(x))\n",
    "# Tokenize the characters of the columns\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(patientsTrimmed['SkinConditions'])\n",
    "# Create and pad sequences of the tokens\n",
    "patientsTrimmed['SkinConditions'] = tokenizer.texts_to_sequences(patientsTrimmed['SkinConditions'])\n",
    "max_length = max(len(seq) for seq in patientsTrimmed['SkinConditions'])\n",
    "testVar = pad_sequences(patientsTrimmed['SkinConditions'], maxlen = max_length, padding = \"post\")\n",
    "patientsTrimmed['SkinConditions'] = testVar.tolist()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a785a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column for preprocessing - ID should have no effect on prediction\n",
    "allergiesNoId = allergies.drop('SFM Id', axis = 1)\n",
    "# Remove all non-digit characters, then replace empty cells with NaN\n",
    "allergiesNoId = allergiesNoId.replace(r'\\D+', '', regex = True).replace('', np.nan)\n",
    "# Set all NaN cells to 0\n",
    "allergiesNoId = allergiesNoId.fillna(0)\n",
    "# Convert entire dataframe to integer\n",
    "allergiesNoId = allergiesNoId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f83d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNoId['AllergiesList'] = allergiesNoId.astype(str).apply(' '.join, axis=1)\n",
    "allergiesNoId['AllergiesList'] = allergiesNoId['AllergiesList'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a60a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Create MultiLabelBinarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "allergiesArr = np.array(allergiesNoId['AllergiesList'])\n",
    "# Multi-hot encode data\n",
    "allergiesArray = mlb.fit_transform(allergiesArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9568019",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNew = mlb.inverse_transform(allergiesArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac504b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesDF = pd.DataFrame(mlb.transform(allergiesArr), columns = mlb.classes_)\n",
    "allergiesDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b032100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold #:  1\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 2s 5ms/step - loss: 0.0171 - val_loss: 0.0084\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0066 - val_loss: 0.0087\n",
      "62/62 [==============================] - 0s 1ms/step\n",
      "X values for test:  [1950    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    3    5    2    6    4    8    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '124', '144962', '1462', '1590', '1600', '1607', '1827', '188', '5468', '5986', '9300')\n",
      "Predicted values as list:  ('0', '103637', '104', '105017', '10541', '10546', '1107', '1149', '1153', '11661', '119', '11996', '121146', '121641', '12344', '124', '124537', '124737', '12522', '130118', '13018', '131996', '132762', '133', '134800', '136', '137792', '13891', '1406', '144962', '1453', '148092', '149', '1496', '1530', '153025', '1586', '1588', '1589', '1590', '1592', '1594', '1595', '1596', '1597', '1598', '1601', '1602', '1604', '1605', '1607', '1609', '1610', '1611', '1613', '1616', '1632', '1658', '1802', '1826', '1827', '185', '186', '1893', '19352', '1967', '1990', '1995', '1997', '2008', '2009', '201', '2023', '203', '204', '2042', '205', '210', '213', '215', '226', '2269', '227', '2270', '240', '24061', '2536', '257', '26137', '263', '26803', '2737', '2819', '28559', '2908', '30442', '3222', '33172', '33173', '35361', '3793', '3799', '38080', '3962', '41609', '418', '41989', '42', '44465', '4550', '459', '4617', '4701', '4824', '4928', '4929', '51508', '5236', '5248', '5272', '5345', '5405', '5467', '5468', '5560', '5825', '5926', '5986', '6020', '607', '6096', '613', '614', '615', '61707', '62', '634', '6416', '6509', '65964', '68258', '68271', '6841', '69227', '7044', '7086', '73771', '7431', '7454', '7529', '754', '7578', '75912', '7737', '799', '80', '800', '8140', '8376', '83935', '8427', '8469', '9127', '9274', '9275', '9276', '9277', '9296', '9300', '9301', '9305', '9308', '9310', '9312', '9314', '9315', '9325', '9337', '9338', '9339', '9341', '9342', '9344', '9346', '9351', '9355', '94128', '9456', '9458', '95438', '96771', '9685')\n",
      "[1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0\n",
      " 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      "0.3488372\n",
      "0.03650831\n",
      "0.92569864\n",
      "0.25182647\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  2\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 2s 5ms/step - loss: 0.0160 - val_loss: 0.0134\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0067\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0056 - val_loss: 0.0072\n",
      "62/62 [==============================] - 0s 1ms/step\n",
      "X values for test:  [2000    0    1    0    0    0    1    0    0    0    0    0    0    0\n",
      "    0    0    0   14    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '15438', '18419', '5443')\n",
      "Predicted values as list:  ('0', '10260', '104630', '10539', '10541', '105611', '112022', '1149', '1153', '11661', '119', '11996', '121146', '124', '124737', '12522', '130118', '131996', '131997', '132762', '133', '133714', '134800', '135153', '136', '136640', '137788', '13891', '1395', '14005', '144962', '145', '1453', '148092', '1487', '149', '1496', '1586', '1587', '1588', '1589', '159', '1590', '1592', '1594', '1597', '1598', '1599', '1601', '1604', '1605', '1607', '1609', '1610', '1613', '1615', '1632', '1658', '1668', '1802', '1826', '1827', '1893', '196', '1964', '1967', '1988', '1995', '1997', '2008', '201', '2013', '2023', '203', '204', '2040', '2042', '2049', '205', '215', '2269', '227', '2270', '2282', '23250', '23454', '240', '24050', '24061', '2536', '257', '26137', '263', '26803', '28559', '28772', '2908', '29231', '29502', '3222', '33172', '33173', '3497', '35361', '3793', '3799', '38080', '3962', '41609', '41728', '41989', '42', '44465', '4550', '459', '4617', '4701', '4824', '4928', '4929', '51508', '5236', '5248', '5272', '5322', '5405', '5443', '5467', '5468', '5825', '5926', '598', '5986', '6020', '607', '608', '6096', '614', '61707', '62', '634', '6416', '6462', '6509', '68258', '68271', '6841', '69227', '7044', '7047', '7086', '73771', '7431', '7454', '75701', '75912', '7651', '7737', '799', '80', '800', '8140', '8376', '83935', '8469', '8512', '9116', '9274', '9275', '9296', '9297', '9300', '9301', '9308', '9310', '9312', '9314', '9315', '9335', '9338', '9339', '9341', '9342', '9344', '9346', '9351', '9357', '9400', '95438', '96771', '9685')\n",
      "[1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3508892\n",
      "0.035459306\n",
      "0.9002417\n",
      "0.24868229\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   3    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]]\n",
      "Running fold #:  3\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0144\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0062\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "62/62 [==============================] - 0s 1ms/step\n",
      "X values for test:  [1946    1    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "    0    0    0    3    7    2    6    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '1600', '1613', '201', '2023', '2787', '9315', '9456')\n",
      "Predicted values as list:  ('0', '10260', '103637', '104630', '105017', '10537', '10541', '1149', '1153', '11661', '11790', '119', '124', '124737', '12522', '130118', '131996', '132762', '133275', '133629', '133714', '134800', '136', '13891', '144962', '1453', '148092', '149', '1496', '152913', '1530', '1586', '1588', '1589', '159', '1590', '1592', '1594', '1595', '1596', '1597', '1598', '1599', '1600', '1601', '1602', '1604', '1605', '1607', '1609', '1610', '1611', '1613', '1615', '1802', '1804', '1826', '1827', '184', '188', '1893', '19352', '1964', '1967', '1988', '1994', '1995', '1997', '2009', '201', '2023', '203', '204', '2042', '2044', '205', '213', '215', '2195', '2269', '227', '2293', '23250', '240', '24045', '24061', '2536', '257', '263', '2819', '2821', '28559', '2908', '30442', '33172', '33173', '35361', '3793', '38080', '3962', '39777', '41609', '41622', '41989', '42', '44465', '4550', '459', '4617', '4701', '4824', '4929', '51508', '5236', '5248', '5272', '52757', '5322', '5405', '5467', '5538', '5926', '5986', '607', '6096', '613', '614', '615', '61707', '61708', '62', '634', '6416', '6509', '68271', '69227', '7086', '73771', '7454', '7737', '7783', '80', '800', '8140', '8376', '83935', '8469', '9274', '9275', '9276', '9277', '9296', '9297', '9300', '9301', '9308', '9310', '9312', '9314', '9315', '9335', '9337', '9338', '9339', '9341', '9342', '9344', '9348', '9351', '9355', '9358', '9371', '9393', '9452', '95426', '95438', '96771', '99100')\n",
      "[1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0\n",
      " 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "0.3248974\n",
      "0.03800363\n",
      "0.9093625\n",
      "0.25408247\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   0 1979]\n",
      "  [   0    1]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  4\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 4s 15ms/step - loss: 0.0304 - val_loss: 0.0122\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0063\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0100\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0131 - val_loss: 0.0156\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0143 - val_loss: 0.0129\n",
      "62/62 [==============================] - 0s 1ms/step\n",
      "X values for test:  [1985    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    3    7    5    2    4    8    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '12522', '1598', '1605', '1805', '201', '2023', '215', '2350', '257', '263', '3799', '5236', '5467', '9315')\n",
      "Predicted values as list:  ('0', '100702', '102', '103637', '104630', '10541', '106344', '1149', '1153', '11661', '11996', '121146', '12344', '124', '124737', '12522', '130118', '13018', '131996', '132762', '134', '134800', '136', '136704', '13891', '1406', '144962', '1453', '148092', '1487', '1496', '1530', '155222', '1586', '1588', '1589', '1590', '1592', '1594', '1595', '1596', '1597', '1598', '1599', '1600', '1601', '1604', '1605', '1607', '1609', '1610', '1613', '1615', '1628', '1802', '1804', '1827', '1830', '185', '1866', '1893', '1995', '1997', '2008', '2009', '201', '2013', '2023', '203', '204', '2042', '2047', '205', '2052', '213', '215', '2269', '227', '2270', '2350', '240', '24022', '24033', '24035', '24061', '24816', '2536', '2565', '257', '263', '26803', '2761', '2819', '28559', '29502', '30442', '30670', '33172', '33173', '35361', '3793', '3799', '38080', '3962', '41609', '4185', '41989', '42', '44465', '4550', '459', '4617', '4701', '4851', '4928', '4929', '51508', '5236', '5248', '5272', '5345', '5405', '5467', '5468', '5560', '5926', '598', '5986', '6011', '6020', '607', '6096', '614', '615', '61707', '61708', '62', '634', '6390', '6416', '6509', '68258', '68271', '6841', '686', '69227', '7047', '7086', '73771', '7454', '7477', '75912', '7737', '7946', '800', '8139', '8140', '81751', '8376', '839', '83935', '8469', '8512', '85249', '9116', '9274', '9275', '9276', '9277', '9297', '9298', '9300', '9305', '9308', '9310', '9312', '9314', '9315', '9335', '9337', '9338', '9339', '9342', '9344', '9346', '9351', '9355', '9358', '9458', '95438', '96771', '97')\n",
      "[1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0\n",
      " 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0\n",
      " 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34336525\n",
      "0.034323942\n",
      "0.90796435\n",
      "0.25001618\n",
      "[[[   0    0]\n",
      "  [   0 1979]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1976    0]\n",
      "  [   3    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  5\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 2s 5ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 1s 4ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 1s 5ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "62/62 [==============================] - 0s 1ms/step\n",
      "X values for test:  [1942    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    7    2    4    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '1600', '1607', '2013', '2023', '2046', '26137', '614', '9375')\n",
      "Predicted values as list:  ('0', '103637', '104630', '105017', '10541', '1107', '113', '1149', '1153', '11661', '11686', '11790', '119', '11996', '121146', '124', '12522', '128565', '130118', '131996', '132762', '134800', '13881', '13891', '1395', '140626', '144962', '1453', '148092', '1487', '149', '1496', '1530', '1586', '1588', '1589', '1590', '1592', '1594', '1595', '1596', '1597', '1598', '1601', '1602', '1604', '1605', '1607', '1609', '1610', '1615', '1802', '1826', '1827', '183', '184', '1893', '1964', '1994', '1995', '1996', '1997', '2008', '201', '2013', '2023', '2028', '203', '204', '2042', '2044', '205', '2050', '213', '215', '22030', '221', '226', '2269', '227', '2288', '2292', '23454', '240', '24061', '24816', '2536', '257', '263', '26803', '2761', '28559', '286', '2908', '30442', '3222', '33172', '33173', '35361', '3565', '3601', '3793', '3799', '38080', '3962', '41508', '41609', '41714', '41729', '4185', '41989', '44465', '4550', '459', '4617', '4637', '4701', '4928', '51508', '5236', '5248', '5272', '5345', '5405', '5467', '5468', '5538', '5560', '5825', '5926', '598', '5986', '6011', '6020', '607', '6096', '613', '614', '61707', '61708', '62', '6416', '6509', '65964', '68', '68258', '68271', '6841', '69227', '7044', '7086', '73771', '7454', '7578', '75912', '7651', '7737', '80', '800', '8140', '8376', '83935', '8469', '9116', '9207', '9274', '9275', '9276', '9277', '9296', '9297', '9298', '9300', '9308', '9310', '9312', '9314', '9315', '9325', '9335', '9337', '9338', '9339', '9341', '9342', '9344', '9348', '9351', '9357', '94128', '9456', '95426', '95438')\n",
      "[1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 0\n",
      " 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1\n",
      " 0 0 0 0 1 0 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0.35430917\n",
      "0.035573\n",
      "0.9153193\n",
      "0.24840252\n",
      "[[[   0    0]\n",
      "  [   0 1979]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "from keras.layers import Average\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7869)\n",
    "\n",
    "fold_count = 1\n",
    "# Train the model for each split\n",
    "# Define the model inside the for loop\n",
    "for train, test in cv.split(input_data,allergiesArray):\n",
    "\n",
    "    n_classes = 731\n",
    "\n",
    "    # Input layer\n",
    "    input_shape = (40,)\n",
    "    inputs = keras.Input(input_shape)\n",
    "\n",
    "    # Hidden layers\n",
    "    x = Dense(256, activation = 'sigmoid')(inputs)\n",
    "    x = Dense(512, activation = 'sigmoid')(x)\n",
    "\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions = Dense(n_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = predictions)\n",
    "    model.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha = 0.35, gamma = 14), optimizer=keras.optimizers.Adam(learning_rate=0.1))\n",
    "    \n",
    "    print(\"Running fold #: \", fold_count)\n",
    "\n",
    "    fold_train_x =input_data[train]\n",
    "    \n",
    "    history = model.fit(\n",
    "    fold_train_x, allergiesArray[train],\n",
    "    epochs = 20, \n",
    "    verbose = 1, \n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "    fold_test_x = input_data[test]\n",
    "    y_true = allergiesArray[test]\n",
    "    \n",
    "    # pred_y = model.predict_classes(fold_test_x, verbose = 1)\n",
    "    probs = model.predict(fold_test_x, verbose = 1)\n",
    "    \n",
    "\n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\\\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    threshold = 0.4\n",
    "    probs = (probs > threshold).astype(int)\n",
    "    # print(\"Predicted y values: \", pred_y[0])\n",
    "    print(\"X values for test: \", fold_test_x[0])\n",
    "    yList = mlb.inverse_transform(y_true)\n",
    "    print(\"Actual y values as list: \", yList[0])\n",
    "    probsList = mlb.inverse_transform(probs)\n",
    "    print(\"Predicted values as list: \", probsList[0])\n",
    "    print(probs[0])\n",
    "    \n",
    "    auc.update_state(y_true, probs)\n",
    "    print(auc.result().numpy())\n",
    "    prec.update_state(y_true, probs)\n",
    "    print(prec.result().numpy())\n",
    "    rec.update_state(y_true, probs)\n",
    "    print(rec.result().numpy())\n",
    "    f1.update_state(y_true, probs)\n",
    "    print(f1.result().numpy())\n",
    "    \n",
    "    matrix = multilabel_confusion_matrix(y_true, probs)\n",
    "    print(matrix)\n",
    "    \n",
    "    # print(\"Accuracy score sklearn: \", accuracy_score(allergiesArray[test], probs))\n",
    "    accuracy = (allergiesArray[test] == probs).all(axis=(0,1)).mean()\n",
    "    # print(\"Accuracy score equation: \", accuracy)\n",
    "\n",
    "    fold_count = fold_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save Keras model as separate file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
