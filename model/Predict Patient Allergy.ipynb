{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create a model used to predict whether the individual patient has an allergy\n",
    "# Use different notebook to load the model and return a prediction\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "# Import both datasets, change to local path when running\n",
    "patients = pd.read_excel(r\"C:\\Users\\me\\OneDrive\\Desktop\\Senior Design\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level2_AI_Patient Traits\")\n",
    "\n",
    "allergies = pd.read_excel(r\"C:\\Users\\me\\OneDrive\\Desktop\\Senior Design\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level1_Patient Allergens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that patient sheet imported correctly\n",
    "# Comment below line before committing\n",
    "# patients['SkinConditions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34eed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm allergy sheet imported correctly\n",
    "# Comment line before committing\n",
    "# allergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb333603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge columns by ID if needed\n",
    "patientAllergies = patients.merge(allergies, on = \"SFM Id\")\n",
    "# Comment line before committing\n",
    "# patientAllergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c97a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID and location columns from dataframe\n",
    "patientsTrimmed = patients.drop(['SFM Id', 'City', 'State', 'Country'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecc338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode Gender column\n",
    "patientsTrimmed['Gender'] = pd.Categorical(patientsTrimmed['Gender'].str.strip())\n",
    "gender_onehot = pd.get_dummies(patientsTrimmed['Gender'], prefix = \"Gender\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('Gender', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(gender_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50d9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode SkinTone column\n",
    "patientsTrimmed['SkinTone'] = pd.Categorical(patientsTrimmed['SkinTone'].str.strip())\n",
    "skintone_onehot = pd.get_dummies(patientsTrimmed['SkinTone'], prefix = \"SkinTone\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinTone', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(skintone_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fc1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode FitzPatrickSkinPhotoType column\n",
    "patientsTrimmed['FitzpatrickSkinPhotoType'] = pd.Categorical(patientsTrimmed['FitzpatrickSkinPhotoType'].str.strip())\n",
    "# Dropping first here since it is a blank variable in the column\n",
    "fitzpatrick_onehot = pd.get_dummies(patientsTrimmed['FitzpatrickSkinPhotoType'], prefix = \"Fitzpatrick\",\n",
    "                                    prefix_sep = \"-\", drop_first = True, dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('FitzpatrickSkinPhotoType', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(fitzpatrick_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c818e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching to TextVectorization (Tokenizer is deprecated)\n",
    "from keras.layers import TextVectorization\n",
    "# Replace commas with whitespace\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].str.replace(',', ' ')\n",
    "# Set the max length based on whitespace characters\n",
    "max_len = patientsTrimmed['SkinConditions'].str.count(' ').max()\n",
    "# Create TextVectorization object, separating on whitespace and using the max_len from earlier\n",
    "vectorizer = TextVectorization(split = 'whitespace', output_sequence_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt using the column we want to convert\n",
    "vectorizer.adapt(patientsTrimmed['SkinConditions'].values)\n",
    "# Reset the column after converting values to vector and placing in array\n",
    "skinConditions = vectorizer(patientsTrimmed['SkinConditions']).numpy()\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinConditions', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5781a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsArr = patientsTrimmed.values\n",
    "input_data = np.concatenate((patientsArr, skinConditions), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b5582",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Old code for SkinConditions conversion - leaving in case we need later\n",
    "# Code to preprocess the SkinConditions column, tokenizing should be more recognizable to keras than regular text\n",
    "## Delete if this idea does not work\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten entries into actual lists\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].apply(lambda x: ' '.join(x))\n",
    "# Tokenize the characters of the columns\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(patientsTrimmed['SkinConditions'])\n",
    "# Create and pad sequences of the tokens\n",
    "patientsTrimmed['SkinConditions'] = tokenizer.texts_to_sequences(patientsTrimmed['SkinConditions'])\n",
    "max_length = max(len(seq) for seq in patientsTrimmed['SkinConditions'])\n",
    "testVar = pad_sequences(patientsTrimmed['SkinConditions'], maxlen = max_length, padding = \"post\")\n",
    "patientsTrimmed['SkinConditions'] = testVar.tolist()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a785a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column for preprocessing - ID should have no effect on prediction\n",
    "allergiesNoId = allergies.drop('SFM Id', axis = 1)\n",
    "# Remove all non-digit characters, then replace empty cells with NaN\n",
    "allergiesNoId = allergiesNoId.replace(r'\\D+', '', regex = True).replace('', np.nan)\n",
    "# Set all NaN cells to 0\n",
    "allergiesNoId = allergiesNoId.fillna(0)\n",
    "# Convert entire dataframe to integer\n",
    "allergiesNoId = allergiesNoId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f83d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNoId['AllergiesList'] = allergiesNoId.astype(str).apply(' '.join, axis=1)\n",
    "allergiesNoId['AllergiesList'] = allergiesNoId['AllergiesList'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a60a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Create MultiLabelBinarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "allergiesArr = np.array(allergiesNoId['AllergiesList'])\n",
    "# Multi-hot encode data\n",
    "allergiesArray = mlb.fit_transform(allergiesArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9568019",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNew = mlb.inverse_transform(allergiesArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac504b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesDF = pd.DataFrame(mlb.transform(allergiesArr), columns = mlb.classes_)\n",
    "allergiesDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2b032100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold #:  1\n",
      "1 AUC:  0.3488372\n",
      "1 prec:  0.5121212\n",
      "1 rec:  0.13526313\n",
      "1 f1:  0.13221318\n",
      "2 AUC:  0.34968635\n",
      "2 prec:  0.007648342\n",
      "2 rec:  0.35790035\n",
      "2 f1:  0.039280396\n",
      "3 AUC:  0.3487258\n",
      "3 prec:  0.011826358\n",
      "3 rec:  0.5575268\n",
      "3 f1:  0.18649349\n",
      "4 AUC:  0.3488437\n",
      "4 prec:  0.008818079\n",
      "4 rec:  0.4169946\n",
      "4 f1:  0.04468945\n",
      "X values for test:  [1950    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    3    5    2    6    4    8    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '124', '144962', '1462', '1590', '1600', '1607', '1827', '188', '5468', '5986', '9300')\n",
      "Predicted values as list:  ('0', '104', '1153', '11661', '121146', '12522', '130118', '136703', '148092', '1496', '1589', '1590', '1592', '1597', '1602', '1610', '1826', '183', '1903', '192', '1997', '2013', '2023', '2044', '215', '24061', '257', '2853', '28559', '30442', '33173', '3799', '38080', '41729', '41989', '4550', '4617', '4638', '4702', '4928', '5272', '54973', '598', '6011', '6020', '613', '62', '634', '6509', '7044', '7454', '75912', '7812', '79', '80', '8140', '8376', '83935', '8469', '9116', '9216', '9296', '9300', '9305', '9308', '9310', '9329', '9335', '9337', '9341', '95438', '96771')\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "Mean AUC:  0.34866932\n",
      "Mean prec:  0.040361814\n",
      "Mean rec:  0.38124457\n",
      "Mean f1:  0.16072552\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  2\n",
      "1 AUC:  0.3508892\n",
      "1 prec:  0.50277776\n",
      "1 rec:  0.13366005\n",
      "1 f1:  0.13292976\n",
      "2 AUC:  0.35181105\n",
      "2 prec:  0.011863815\n",
      "2 rec:  0.5608217\n",
      "2 f1:  0.18360639\n",
      "3 AUC:  0.35160792\n",
      "3 prec:  0.009647035\n",
      "3 rec:  0.49758324\n",
      "3 f1:  0.08282143\n",
      "4 AUC:  0.35085914\n",
      "4 prec:  0.011288412\n",
      "4 rec:  0.5794844\n",
      "4 f1:  0.20020047\n",
      "X values for test:  [2000    0    1    0    0    0    1    0    0    0    0    0    0    0\n",
      "    0    0    0   14    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '15438', '18419', '5443')\n",
      "Predicted values as list:  ('0', '103637', '104630', '10537', '1107', '1130', '1153', '124', '12522', '130118', '140625', '140626', '1487', '1496', '1589', '159', '1592', '1594', '1595', '1598', '1599', '1604', '1605', '1607', '1609', '1610', '1632', '1802', '1827', '1866', '19352', '1964', '1967', '1994', '1995', '2008', '201', '204', '2042', '2046', '209', '210', '213', '215', '227', '2287', '2383', '24042', '24816', '2536', '263', '2737', '2908', '30442', '33172', '3405', '42006', '459', '4615', '4637', '4928', '5500', '5823', '6011', '607', '613', '6509', '671', '71869', '7431', '764', '7737', '7783', '799', '8139', '8386', '83935', '8469', '9274', '9276', '9296', '9300', '9308', '9310', '9314', '9338', '9364', '9418', '9456', '95426')\n",
      "[1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Mean AUC:  0.3511042\n",
      "Mean prec:  0.03926386\n",
      "Mean rec:  0.47207305\n",
      "Mean f1:  0.195792\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   3    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]]\n",
      "Running fold #:  3\n",
      "1 AUC:  0.3248974\n",
      "1 prec:  0.5156566\n",
      "1 rec:  0.13863806\n",
      "1 f1:  0.1346843\n",
      "2 AUC:  0.322599\n",
      "2 prec:  0.009598309\n",
      "2 rec:  0.45868695\n",
      "2 f1:  0.065896995\n",
      "3 AUC:  0.32480195\n",
      "3 prec:  0.007468876\n",
      "3 rec:  0.34482992\n",
      "3 f1:  0.048293285\n",
      "4 AUC:  0.32491538\n",
      "4 prec:  0.007588741\n",
      "4 rec:  0.36526582\n",
      "4 f1:  0.040000107\n",
      "X values for test:  [1946    1    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "    0    0    0    3    7    2    6    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '1600', '1613', '201', '2023', '2787', '9315', '9456')\n",
      "Predicted values as list:  ('0', '103637', '10546', '1149', '119', '12344', '12522', '129742', '130118', '133629', '13891', '144962', '1453', '1582', '1587', '1590', '1596', '1597', '1598', '1610', '184', '190', '1903', '1990', '2007', '2009', '2013', '203', '2042', '2047', '205', '2053', '20759', '215', '227', '2307', '23454', '2536', '28559', '28772', '2908', '30442', '340', '41609', '44465', '459', '4615', '4618', '4928', '5236', '5272', '52757', '5345', '545', '5538', '6011', '607', '613', '614', '61707', '634', '6416', '68258', '68271', '6841', '7086', '73771', '7669', '7737', '799', '80', '8172', '8376', '83935', '9116', '9289', '9296', '9298', '9312', '9335', '9339', '9344', '9357', '9404', '94128', '9456')\n",
      "[1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Mean AUC:  0.32458296\n",
      "Mean prec:  0.035852004\n",
      "Mean rec:  0.4178831\n",
      "Mean f1:  0.17109242\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold #:  4\n",
      "1 AUC:  0.34336525\n",
      "1 prec:  0.25555837\n",
      "1 rec:  0.1408382\n",
      "1 f1:  0.1378429\n",
      "2 AUC:  0.34418455\n",
      "2 prec:  0.011345779\n",
      "2 rec:  0.56495404\n",
      "2 f1:  0.18066192\n",
      "3 AUC:  0.34278378\n",
      "3 prec:  0.009244991\n",
      "3 rec:  0.46776664\n",
      "3 f1:  0.07648648\n",
      "4 AUC:  0.34337705\n",
      "4 prec:  0.011249365\n",
      "4 rec:  0.5951685\n",
      "4 f1:  0.18961269\n",
      "X values for test:  [1985    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    3    7    5    2    4    8    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '12522', '1598', '1605', '1805', '201', '2023', '215', '2350', '257', '263', '3799', '5236', '5467', '9315')\n",
      "Predicted values as list:  ('0', '103637', '104630', '105017', '119', '11996', '124', '12522', '128', '13018', '131996', '132762', '133', '136', '1496', '1582', '1586', '1590', '1596', '1597', '1599', '1600', '1601', '1605', '1610', '1613', '1635', '1802', '1826', '183', '184', '185', '188', '1903', '2023', '2040', '205', '213', '226', '2272', '2292', '230', '23454', '24023', '24061', '26137', '28559', '32880', '33172', '340', '3405', '3565', '3793', '41609', '4550', '4929', '51508', '52757', '5322', '5405', '5467', '5986', '614', '62', '680', '68271', '69227', '7086', '73771', '7454', '7651', '8140', '83935', '9289', '9298', '9308', '9310', '9315', '9325', '9337', '9338', '9342', '9351', '9358', '9375', '94128', '9456', '95438')\n",
      "[1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Mean AUC:  0.343346\n",
      "Mean prec:  0.041784063\n",
      "Mean rec:  0.5048733\n",
      "Mean f1:  0.20303026\n",
      "[[[   0    0]\n",
      "  [   0 1979]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1976    0]\n",
      "  [   3    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  5\n",
      "1 AUC:  0.35430917\n",
      "1 prec:  0.20667003\n",
      "1 rec:  0.13776611\n",
      "1 f1:  0.13347903\n",
      "2 AUC:  0.35530764\n",
      "2 prec:  0.012820832\n",
      "2 rec:  0.6580437\n",
      "2 f1:  0.21389394\n",
      "3 AUC:  0.35522693\n",
      "3 prec:  0.011299126\n",
      "3 rec:  0.5425088\n",
      "3 f1:  0.1940706\n",
      "4 AUC:  0.35454512\n",
      "4 prec:  0.012856886\n",
      "4 rec:  0.6453786\n",
      "4 f1:  0.21928047\n",
      "X values for test:  [1942    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    7    2    4    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '1600', '1607', '2013', '2023', '2046', '26137', '614', '9375')\n",
      "Predicted values as list:  ('0', '10260', '104630', '10537', '1130', '1149', '1153', '119', '11996', '124737', '12522', '131996', '134800', '13891', '1487', '1496', '151557', '1589', '159', '1590', '1605', '1613', '1665', '183', '184', '185', '1903', '1988', '2008', '2023', '2028', '2031', '205', '2053', '210', '215', '227', '2272', '22833', '2292', '2293', '240', '24071', '24816', '2536', '26137', '26803', '28559', '3127', '32880', '3565', '38080', '4617', '4909', '5236', '5322', '5345', '5467', '5468', '5823', '598', '5986', '6020', '62', '634', '7086', '75912', '7737', '799', '9116', '9275', '9277', '9296', '9308', '9310', '9339', '9342', '9348', '9351', '9357', '9375', '94128', '9456', '9465', '95426', '95438', '96771')\n",
      "[1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "Mean AUC:  0.3543894\n",
      "Mean prec:  0.038284536\n",
      "Mean rec:  0.44442198\n",
      "Mean f1:  0.19309367\n",
      "[[[   0    0]\n",
      "  [   0 1979]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   0    0]]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "from keras.layers import Average\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7869)\n",
    "\n",
    "fold_count = 1\n",
    "# Train the model for each split\n",
    "# Define the model inside the for loop\n",
    "for train, test in cv.split(input_data,allergiesArray):\n",
    "\n",
    "    n_classes = 731\n",
    "\n",
    "    # Input layer\n",
    "    input_shape = (40,)\n",
    "    inputs = keras.Input(input_shape)\n",
    "    # Hidden layers\n",
    "    x1 = Dense(256, activation = 'sigmoid')(inputs)\n",
    "    x1 = Dense(512, activation = 'sigmoid')(x1)\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions1 = Dense(n_classes, activation='sigmoid')(x1)\n",
    "    \n",
    "    model1 = keras.Model(inputs = inputs, outputs = predictions1)\n",
    "    model1.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha = 0.35, gamma = 14), optimizer=keras.optimizers.Adam(learning_rate=0.1))\n",
    "    \n",
    "    x2 = Dense(256, activation = 'sigmoid')(inputs)\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions2 = Dense(n_classes, activation='sigmoid')(x2)\n",
    "    \n",
    "    model2 = keras.Model(inputs = inputs, outputs = predictions2)\n",
    "    model2.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha = 0.1, gamma = 10), optimizer=keras.optimizers.SGD(learning_rate=0.05))\n",
    "    \n",
    "    x3 = Dense(385, activation = 'sigmoid')(inputs)\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions3 = Dense(n_classes, activation='sigmoid')(x3)\n",
    "    \n",
    "    model3 = keras.Model(inputs = inputs, outputs = predictions3)\n",
    "    model3.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha = 0.5, gamma = .2), optimizer=keras.optimizers.Adam(learning_rate=0.01))\n",
    "    \n",
    "    x4 = Dense(256, activation = 'sigmoid')(inputs)\n",
    "    x4 = Dense(512, activation = 'sigmoid')(x4)\n",
    "    x4 = Dense(1024, activation = 'sigmoid')(x4)\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions4 = Dense(n_classes, activation='sigmoid')(x4)\n",
    "    \n",
    "    model4 = keras.Model(inputs = inputs, outputs = predictions4)\n",
    "    model4.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha = 0.2, gamma = 5), optimizer=keras.optimizers.Adam(learning_rate=0.2))\n",
    "    \n",
    "    print(\"Running fold #: \", fold_count)\n",
    "\n",
    "    fold_train_x =input_data[train]\n",
    "    \n",
    "    history1 = model1.fit(\n",
    "    fold_train_x, allergiesArray[train],\n",
    "    epochs = 20, \n",
    "    verbose = 0, \n",
    "    batch_size = 20, \n",
    "    validation_split=0.1\n",
    "    )\n",
    "    \n",
    "    history2 = model1.fit(\n",
    "    fold_train_x, allergiesArray[train],\n",
    "    epochs = 10, \n",
    "    verbose = 0, \n",
    "    batch_size = 4, \n",
    "    validation_split=0.3\n",
    "    )\n",
    "        \n",
    "    history3 = model1.fit(\n",
    "    fold_train_x, allergiesArray[train],\n",
    "    epochs = 50, \n",
    "    verbose = 0, \n",
    "    batch_size = 50, \n",
    "    validation_split=0.1\n",
    "    )\n",
    "            \n",
    "    history4 = model1.fit(\n",
    "    fold_train_x, allergiesArray[train],\n",
    "    epochs = 15, \n",
    "    verbose = 0, \n",
    "    batch_size = 10, \n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "    fold_test_x = input_data[test]\n",
    "    y_true = allergiesArray[test]\n",
    "    \n",
    "    # pred_y = model.predict_classes(fold_test_x, verbose = 1)\n",
    "    probs1 = model1.predict(fold_test_x, verbose = 0)\n",
    "    probs2 = model2.predict(fold_test_x, verbose = 0)\n",
    "    probs3 = model3.predict(fold_test_x, verbose = 0)\n",
    "    probs4 = model4.predict(fold_test_x, verbose = 0)\n",
    "    \n",
    "    probs = (probs1 + probs2 + probs3 + probs4) / 4.0\n",
    "    threshold = 0.5\n",
    "    probs1 = (probs1 > threshold).astype(int)\n",
    "    probs2 = (probs2 > threshold).astype(int)\n",
    "    probs3 = (probs3 > threshold).astype(int)\n",
    "    probs4 = (probs4 > threshold).astype(int)\n",
    "    probs = (probs > threshold).astype(int)\n",
    "    \n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\\\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    auc.update_state(y_true, probs1)\n",
    "    print(\"1 AUC: \", auc.result().numpy())\n",
    "    prec.update_state(y_true, probs1)\n",
    "    print(\"1 prec: \", prec.result().numpy())\n",
    "    rec.update_state(y_true, probs1)\n",
    "    print(\"1 rec: \", rec.result().numpy())\n",
    "    f1.update_state(y_true, probs1)\n",
    "    print(\"1 f1: \", f1.result().numpy())\n",
    "    \n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\\\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    auc.update_state(y_true, probs2)\n",
    "    print(\"2 AUC: \", auc.result().numpy())\n",
    "    prec.update_state(y_true, probs2)\n",
    "    print(\"2 prec: \", prec.result().numpy())\n",
    "    rec.update_state(y_true, probs2)\n",
    "    print(\"2 rec: \", rec.result().numpy())\n",
    "    f1.update_state(y_true, probs2)\n",
    "    print(\"2 f1: \", f1.result().numpy())\n",
    "    \n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    auc.update_state(y_true, probs3)\n",
    "    print(\"3 AUC: \", auc.result().numpy())\n",
    "    prec.update_state(y_true, probs3)\n",
    "    print(\"3 prec: \", prec.result().numpy())\n",
    "    rec.update_state(y_true, probs3)\n",
    "    print(\"3 rec: \", rec.result().numpy())\n",
    "    f1.update_state(y_true, probs3)\n",
    "    print(\"3 f1: \", f1.result().numpy())\n",
    "    \n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\\\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    auc.update_state(y_true, probs4)\n",
    "    print(\"4 AUC: \", auc.result().numpy())\n",
    "    prec.update_state(y_true, probs4)\n",
    "    print(\"4 prec: \", prec.result().numpy())\n",
    "    rec.update_state(y_true, probs4)\n",
    "    print(\"4 rec: \", rec.result().numpy())\n",
    "    f1.update_state(y_true, probs4)\n",
    "    print(\"4 f1: \", f1.result().numpy())\n",
    "    \n",
    "    \n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\\\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    # print(\"Predicted y values: \", pred_y[0])\n",
    "    print(\"X values for test: \", fold_test_x[0])\n",
    "    yList = mlb.inverse_transform(y_true)\n",
    "    print(\"Actual y values as list: \", yList[0])\n",
    "    probsList = mlb.inverse_transform(probs)\n",
    "    print(\"Predicted values as list: \", probsList[0])\n",
    "    print(probs[0])\n",
    "    \n",
    "    auc.update_state(y_true, probs)\n",
    "    print(\"Mean AUC: \", auc.result().numpy())\n",
    "    prec.update_state(y_true, probs)\n",
    "    print(\"Mean prec: \", prec.result().numpy())\n",
    "    rec.update_state(y_true, probs)\n",
    "    print(\"Mean rec: \", rec.result().numpy())\n",
    "    f1.update_state(y_true, probs)\n",
    "    print(\"Mean f1: \", f1.result().numpy())\n",
    "    \n",
    "    matrix = multilabel_confusion_matrix(y_true, probs)\n",
    "    print(matrix)\n",
    "    \n",
    "    # print(\"Accuracy score sklearn: \", accuracy_score(allergiesArray[test], probs))\n",
    "    accuracy = (allergiesArray[test] == probs).all(axis=(0,1)).mean()\n",
    "    # print(\"Accuracy score equation: \", accuracy)\n",
    "\n",
    "    fold_count = fold_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save Keras model as separate file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
