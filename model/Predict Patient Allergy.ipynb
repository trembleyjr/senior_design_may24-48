{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1fc624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 19:13:30.866718: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Code to create a model used to predict whether the individual patient has an allergy\n",
    "# Use different notebook to load the model and return a prediction\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "# Import both datasets, change to local path when running\n",
    "patients = pd.read_excel(r\"/Users/ellagodfrey/Desktop/492/patients.xlsx\", sheet_name=\"Level2_AI_Patient Traits\")\n",
    "\n",
    "allergies = pd.read_excel(r\"/Users/ellagodfrey/Desktop/492/patients.xlsx\", sheet_name=\"Level1_Patient Allergens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that patient sheet imported correctly\n",
    "# Comment below line before committing\n",
    "# patients['SkinConditions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34eed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm allergy sheet imported correctly\n",
    "# Comment line before committing\n",
    "# allergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb333603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge columns by ID if needed\n",
    "patientAllergies = patients.merge(allergies, on = \"SFM Id\")\n",
    "# Comment line before committing\n",
    "# patientAllergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c97a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID and location columns from dataframe\n",
    "patientsTrimmed = patients.drop(['SFM Id', 'City', 'State', 'Country'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecc338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode Gender column\n",
    "patientsTrimmed['Gender'] = pd.Categorical(patientsTrimmed['Gender'].str.strip())\n",
    "gender_onehot = pd.get_dummies(patientsTrimmed['Gender'], prefix = \"Gender\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('Gender', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(gender_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50d9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode SkinTone column\n",
    "patientsTrimmed['SkinTone'] = pd.Categorical(patientsTrimmed['SkinTone'].str.strip())\n",
    "skintone_onehot = pd.get_dummies(patientsTrimmed['SkinTone'], prefix = \"SkinTone\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinTone', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(skintone_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fc1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode FitzPatrickSkinPhotoType column\n",
    "patientsTrimmed['FitzpatrickSkinPhotoType'] = pd.Categorical(patientsTrimmed['FitzpatrickSkinPhotoType'].str.strip())\n",
    "# Dropping first here since it is a blank variable in the column\n",
    "fitzpatrick_onehot = pd.get_dummies(patientsTrimmed['FitzpatrickSkinPhotoType'], prefix = \"Fitzpatrick\",\n",
    "                                    prefix_sep = \"-\", drop_first = True, dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('FitzpatrickSkinPhotoType', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(fitzpatrick_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c818e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching to TextVectorization (Tokenizer is deprecated)\n",
    "from keras.layers import TextVectorization\n",
    "# Replace commas with whitespace\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].str.replace(',', ' ')\n",
    "# Set the max length based on whitespace characters\n",
    "max_len = patientsTrimmed['SkinConditions'].str.count(' ').max()\n",
    "# Create TextVectorization object, separating on whitespace and using the max_len from earlier\n",
    "vectorizer = TextVectorization(split = 'whitespace', output_sequence_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537f2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt using the column we want to convert\n",
    "vectorizer.adapt(patientsTrimmed['SkinConditions'].values)\n",
    "# Reset the column after converting values to vector and placing in array\n",
    "skinConditions = vectorizer(patientsTrimmed['SkinConditions']).numpy()\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinConditions', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5781a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsArr = patientsTrimmed.values\n",
    "input_data = np.concatenate((patientsArr, skinConditions), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "255b5582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Old code for SkinConditions conversion - leaving in case we need later\\n# Code to preprocess the SkinConditions column, tokenizing should be more recognizable to keras than regular text\\n## Delete if this idea does not work\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras.preprocessing.sequence import pad_sequences\\n\\n# Flatten entries into actual lists\\npatientsTrimmed[\\'SkinConditions\\'] = patientsTrimmed[\\'SkinConditions\\'].apply(lambda x: \\' \\'.join(x))\\n# Tokenize the characters of the columns\\ntokenizer = Tokenizer()\\ntokenizer.fit_on_texts(patientsTrimmed[\\'SkinConditions\\'])\\n# Create and pad sequences of the tokens\\npatientsTrimmed[\\'SkinConditions\\'] = tokenizer.texts_to_sequences(patientsTrimmed[\\'SkinConditions\\'])\\nmax_length = max(len(seq) for seq in patientsTrimmed[\\'SkinConditions\\'])\\ntestVar = pad_sequences(patientsTrimmed[\\'SkinConditions\\'], maxlen = max_length, padding = \"post\")\\npatientsTrimmed[\\'SkinConditions\\'] = testVar.tolist()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Old code for SkinConditions conversion - leaving in case we need later\n",
    "# Code to preprocess the SkinConditions column, tokenizing should be more recognizable to keras than regular text\n",
    "## Delete if this idea does not work\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten entries into actual lists\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].apply(lambda x: ' '.join(x))\n",
    "# Tokenize the characters of the columns\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(patientsTrimmed['SkinConditions'])\n",
    "# Create and pad sequences of the tokens\n",
    "patientsTrimmed['SkinConditions'] = tokenizer.texts_to_sequences(patientsTrimmed['SkinConditions'])\n",
    "max_length = max(len(seq) for seq in patientsTrimmed['SkinConditions'])\n",
    "testVar = pad_sequences(patientsTrimmed['SkinConditions'], maxlen = max_length, padding = \"post\")\n",
    "patientsTrimmed['SkinConditions'] = testVar.tolist()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a785a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column for preprocessing - ID should have no effect on prediction\n",
    "allergiesNoId = allergies.drop('SFM Id', axis = 1)\n",
    "# Remove all non-digit characters, then replace empty cells with NaN\n",
    "allergiesNoId = allergiesNoId.replace(r'\\D+', '', regex = True).replace('', np.nan)\n",
    "# Set all NaN cells to 0\n",
    "allergiesNoId = allergiesNoId.fillna(0)\n",
    "# Convert entire dataframe to integer\n",
    "allergiesNoId = allergiesNoId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f83d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNoId['AllergiesList'] = allergiesNoId.astype(str).apply(' '.join, axis=1)\n",
    "allergiesNoId['AllergiesList'] = allergiesNoId['AllergiesList'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a60a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Create MultiLabelBinarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "allergiesArr = np.array(allergiesNoId['AllergiesList'])\n",
    "# Multi-hot encode data\n",
    "allergiesArray = mlb.fit_transform(allergiesArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9568019",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNew = mlb.inverse_transform(allergiesArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac504b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         int64\n",
       "100612    int64\n",
       "100613    int64\n",
       "100702    int64\n",
       "100857    int64\n",
       "          ...  \n",
       "9804      int64\n",
       "98288     int64\n",
       "99100     int64\n",
       "9926      int64\n",
       "99356     int64\n",
       "Length: 731, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergiesDF = pd.DataFrame(mlb.transform(allergiesArr), columns = mlb.classes_)\n",
    "allergiesDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b032100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold #:  1\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 6s 20ms/step - loss: 0.0060 - precision: 0.0661 - recall: 0.2249 - val_loss: 0.0069 - val_precision: 0.1082 - val_recall: 0.1673\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0032 - precision: 0.1365 - recall: 0.1416 - val_loss: 0.0024 - val_precision: 0.3525 - val_recall: 0.1487\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 5s 27ms/step - loss: 0.0025 - precision: 0.2441 - recall: 0.1394 - val_loss: 0.0019 - val_precision: 0.1301 - val_recall: 0.1463\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 5s 24ms/step - loss: 0.0016 - precision: 0.3003 - recall: 0.1343 - val_loss: 0.0019 - val_precision: 0.2505 - val_recall: 0.1409\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0016 - precision: 0.3398 - recall: 0.1335 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 0.1406\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0015 - precision: 0.3626 - recall: 0.1336 - val_loss: 0.0017 - val_precision: 0.3342 - val_recall: 0.1409\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0014 - precision: 0.4263 - recall: 0.1333 - val_loss: 0.0014 - val_precision: 0.5000 - val_recall: 0.1406\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0015 - precision: 0.4091 - recall: 0.1335 - val_loss: 0.0021 - val_precision: 0.5003 - val_recall: 0.1407\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 3s 16ms/step - loss: 0.0023 - precision: 0.3938 - recall: 0.1338 - val_loss: 0.0022 - val_precision: 0.3422 - val_recall: 0.1443\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 3s 18ms/step - loss: 0.0017 - precision: 0.3908 - recall: 0.1340 - val_loss: 0.0020 - val_precision: 0.2503 - val_recall: 0.1408\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0023 - precision: 0.3935 - recall: 0.1336 - val_loss: 0.0025 - val_precision: 1.0000 - val_recall: 0.1406\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0025 - precision: 0.4769 - recall: 0.1334 - val_loss: 0.0027 - val_precision: 0.2503 - val_recall: 0.1408\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 5s 25ms/step - loss: 0.0017 - precision: 0.4271 - recall: 0.1339 - val_loss: 0.0024 - val_precision: 1.0000 - val_recall: 0.1406\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0024 - precision: 0.4252 - recall: 0.1344 - val_loss: 0.0031 - val_precision: 0.5003 - val_recall: 0.1407\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0028 - precision: 0.4391 - recall: 0.1335 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 0.1406\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0022 - precision: 0.4111 - recall: 0.1338 - val_loss: 0.0025 - val_precision: 0.2508 - val_recall: 0.1410\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0022 - precision: 0.3944 - recall: 0.1339 - val_loss: 0.0029 - val_precision: 0.3342 - val_recall: 0.1409\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0031 - precision: 0.4359 - recall: 0.1336 - val_loss: 0.0036 - val_precision: 0.5003 - val_recall: 0.1407\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0027 - precision: 0.4273 - recall: 0.1345 - val_loss: 0.0030 - val_precision: 0.5006 - val_recall: 0.1408\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0026 - precision: 0.3888 - recall: 0.1347 - val_loss: 0.0021 - val_precision: 0.2543 - val_recall: 0.1430\n",
      "62/62 [==============================] - 0s 4ms/step\n",
      "Best F1 score: 0.25255556078385605\n",
      "Optimal threshold: 0.1\n",
      "Precision: 0.21295176806415383\n",
      "Recall: 0.9888614686853865\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[   0 1980]\n",
      "  [   0    0]]\n",
      "\n",
      " [[   0 1980]\n",
      "  [   0    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[   0 1979]\n",
      "  [   0    1]]\n",
      "\n",
      " [[   0 1980]\n",
      "  [   0    0]]]\n",
      "Running fold #:  2\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 6s 20ms/step - loss: 0.0277 - precision_1: 0.0759 - recall_1: 0.2258 - val_loss: 0.0172 - val_precision_1: 0.1202 - val_recall_1: 0.1478\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0092 - precision_1: 0.1731 - recall_1: 0.1402 - val_loss: 0.0084 - val_precision_1: 0.3338 - val_recall_1: 0.1369\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 5s 26ms/step - loss: 0.0071 - precision_1: 0.2571 - recall_1: 0.1345 - val_loss: 0.0079 - val_precision_1: 0.3346 - val_recall_1: 0.1372\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0056 - precision_1: 0.3003 - recall_1: 0.1344 - val_loss: 0.0068 - val_precision_1: 0.5006 - val_recall_1: 0.1369\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0048 - precision_1: 0.4021 - recall_1: 0.1340 - val_loss: 0.0056 - val_precision_1: 1.0000 - val_recall_1: 0.1367\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0041 - precision_1: 0.4029 - recall_1: 0.1345 - val_loss: 0.0054 - val_precision_1: 0.3346 - val_recall_1: 0.1372\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0037 - precision_1: 0.4059 - recall_1: 0.1344 - val_loss: 0.0052 - val_precision_1: 1.0000 - val_recall_1: 0.1367\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0035 - precision_1: 0.3771 - recall_1: 0.1358 - val_loss: 0.0079 - val_precision_1: 0.5006 - val_recall_1: 0.1369\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0047 - precision_1: 0.5018 - recall_1: 0.1357 - val_loss: 0.0065 - val_precision_1: 1.0000 - val_recall_1: 0.1367\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0035 - precision_1: 0.4532 - recall_1: 0.1357 - val_loss: 0.0054 - val_precision_1: 0.5003 - val_recall_1: 0.1368\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0035 - precision_1: 0.4219 - recall_1: 0.1363 - val_loss: 0.0050 - val_precision_1: 0.5000 - val_recall_1: 0.1367\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0035 - precision_1: 0.4845 - recall_1: 0.1359 - val_loss: 0.0051 - val_precision_1: 1.0000 - val_recall_1: 0.1367\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0039 - precision_1: 0.4873 - recall_1: 0.1350 - val_loss: 0.0061 - val_precision_1: 0.5003 - val_recall_1: 0.1368\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0056 - precision_1: 0.4635 - recall_1: 0.1372 - val_loss: 0.0079 - val_precision_1: 1.0000 - val_recall_1: 0.1367\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0069 - precision_1: 0.4465 - recall_1: 0.1403 - val_loss: 0.0064 - val_precision_1: 0.3346 - val_recall_1: 0.1372\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 4s 23ms/step - loss: 0.0054 - precision_1: 0.4226 - recall_1: 0.1365 - val_loss: 0.0066 - val_precision_1: 0.5003 - val_recall_1: 0.1368\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 5s 23ms/step - loss: 0.0080 - precision_1: 0.4340 - recall_1: 0.1434 - val_loss: 0.0098 - val_precision_1: 0.5016 - val_recall_1: 0.1371\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 5s 25ms/step - loss: 0.0081 - precision_1: 0.4781 - recall_1: 0.1393 - val_loss: 0.0112 - val_precision_1: 1.0000 - val_recall_1: 0.1367\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 5s 26ms/step - loss: 0.0092 - precision_1: 0.4558 - recall_1: 0.1343 - val_loss: 0.0129 - val_precision_1: 0.5000 - val_recall_1: 0.1367\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 6s 32ms/step - loss: 0.0120 - precision_1: 0.4872 - recall_1: 0.1343 - val_loss: 0.0148 - val_precision_1: 0.5041 - val_recall_1: 0.1378\n",
      "62/62 [==============================] - 1s 11ms/step\n",
      "Best F1 score: 0.24967831871029764\n",
      "Optimal threshold: 0.1\n",
      "Precision: 0.2331874735540149\n",
      "Recall: 0.967373791621912\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   3    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]]\n",
      "Running fold #:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "198/198 [==============================] - 8s 26ms/step - loss: 0.0101 - precision_2: 0.0681 - recall_2: 0.2194 - val_loss: 0.0075 - val_precision_2: 0.1439 - val_recall_2: 0.1580\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 4s 23ms/step - loss: 0.0046 - precision_2: 0.1417 - recall_2: 0.1458 - val_loss: 0.0046 - val_precision_2: 0.1241 - val_recall_2: 0.1533\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0028 - precision_2: 0.2530 - recall_2: 0.1351 - val_loss: 0.0039 - val_precision_2: 0.2511 - val_recall_2: 0.1379\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0022 - precision_2: 0.3298 - recall_2: 0.1333 - val_loss: 0.0030 - val_precision_2: 0.3346 - val_recall_2: 0.1378\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 5s 26ms/step - loss: 0.0023 - precision_2: 0.3823 - recall_2: 0.1335 - val_loss: 0.0035 - val_precision_2: 0.5000 - val_recall_2: 0.1372\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 5s 25ms/step - loss: 0.0018 - precision_2: 0.4324 - recall_2: 0.1335 - val_loss: 0.0023 - val_precision_2: 0.3361 - val_recall_2: 0.1384\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0016 - precision_2: 0.3844 - recall_2: 0.1334 - val_loss: 0.0025 - val_precision_2: 0.2506 - val_recall_2: 0.1376\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0017 - precision_2: 0.4742 - recall_2: 0.1333 - val_loss: 0.0022 - val_precision_2: 0.5003 - val_recall_2: 0.1373\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 6s 31ms/step - loss: 0.0023 - precision_2: 0.4081 - recall_2: 0.1337 - val_loss: 0.0020 - val_precision_2: 0.3354 - val_recall_2: 0.1381\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 5s 26ms/step - loss: 0.0014 - precision_2: 0.4121 - recall_2: 0.1339 - val_loss: 0.0018 - val_precision_2: 0.2513 - val_recall_2: 0.1379\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0019 - precision_2: 0.5204 - recall_2: 0.1333 - val_loss: 0.0021 - val_precision_2: 0.5107 - val_recall_2: 0.1402\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0023 - precision_2: 0.4743 - recall_2: 0.1340 - val_loss: 0.0029 - val_precision_2: 1.0000 - val_recall_2: 0.1372\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 3s 16ms/step - loss: 0.0030 - precision_2: 0.4636 - recall_2: 0.1347 - val_loss: 0.0028 - val_precision_2: 0.3335 - val_recall_2: 0.1373\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0037 - precision_2: 0.4038 - recall_2: 0.1339 - val_loss: 0.0041 - val_precision_2: 0.3413 - val_recall_2: 0.1405\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0044 - precision_2: 0.4267 - recall_2: 0.1346 - val_loss: 0.0044 - val_precision_2: 0.3338 - val_recall_2: 0.1374\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 3s 16ms/step - loss: 0.0035 - precision_2: 0.3600 - recall_2: 0.1354 - val_loss: 0.0056 - val_precision_2: 0.5000 - val_recall_2: 0.1372\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0051 - precision_2: 0.4350 - recall_2: 0.1355 - val_loss: 0.0110 - val_precision_2: 0.3721 - val_recall_2: 0.1532\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0064 - precision_2: 0.3541 - recall_2: 0.1379 - val_loss: 0.0049 - val_precision_2: 0.5047 - val_recall_2: 0.1385\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0057 - precision_2: 0.4182 - recall_2: 0.1361 - val_loss: 0.0065 - val_precision_2: 0.2508 - val_recall_2: 0.1377\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0064 - precision_2: 0.4350 - recall_2: 0.1346 - val_loss: 0.0069 - val_precision_2: 0.3344 - val_recall_2: 0.1377\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "Best F1 score: 0.25365175583675664\n",
      "Optimal threshold: 0.1\n",
      "Precision: 0.2363919938059391\n",
      "Recall: 0.9672754430035984\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[   0 1978]\n",
      "  [   0    2]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  4\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 7s 23ms/step - loss: 0.0366 - precision_3: 0.0817 - recall_3: 0.2300 - val_loss: 0.0158 - val_precision_3: 0.0782 - val_recall_3: 0.1846\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0103 - precision_3: 0.1609 - recall_3: 0.1394 - val_loss: 0.0088 - val_precision_3: 0.3344 - val_recall_3: 0.1393\n",
      "Epoch 3/20\n",
      " 75/198 [==========>...................] - ETA: 2s - loss: 0.0076 - precision_3: 0.2447 - recall_3: 0.1314"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import multilabel_confusion_matrix, precision_score, recall_score, f1_score\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7869)\n",
    "\n",
    "fold_count = 1\n",
    "# Train the model for each split\n",
    "# Define the model inside the for loop\n",
    "for train, test in cv.split(input_data, allergiesArray):\n",
    "\n",
    "    n_classes = 731\n",
    "\n",
    "    # Input layer\n",
    "    input_shape = (40,)\n",
    "    inputs = keras.Input(input_shape)\n",
    "\n",
    "    # Hidden layers\n",
    "    x = Dense(256, activation='sigmoid')(inputs)\n",
    "    x = Dense(512, activation='sigmoid')(x)\n",
    "\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions = Dense(n_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha=0.35, gamma=14),\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                  metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\n",
    "    print(\"Running fold #: \", fold_count)\n",
    "\n",
    "    fold_train_x = input_data[train]\n",
    "\n",
    "    history = model.fit(\n",
    "        fold_train_x, allergiesArray[train],\n",
    "        epochs=20,\n",
    "        verbose=1,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    fold_test_x = input_data[test]\n",
    "    y_true = allergiesArray[test]\n",
    "\n",
    "    # Predict probabilities\n",
    "    probs = model.predict(fold_test_x, verbose=1)\n",
    "\n",
    "    # Dynamic threshold optimization based on F1 score\n",
    "    best_f1 = 0\n",
    "    optimal_threshold = 0\n",
    "    for t in np.arange(0.1, 1, 0.1):\n",
    "        y_pred = (probs > t).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            optimal_threshold = t\n",
    "\n",
    "    print(\"Best F1 score:\", best_f1)\n",
    "    print(\"Optimal threshold:\", optimal_threshold)\n",
    "\n",
    "    # Apply threshold\n",
    "    y_pred = (probs > optimal_threshold).astype(int)\n",
    "\n",
    "    # Compute precision and recall\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    # Compute multilabel confusion matrix\n",
    "    matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    print(matrix)\n",
    "\n",
    "    fold_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save Keras model as separate file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
