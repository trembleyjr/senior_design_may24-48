{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f1fc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create a model used to predict whether the individual patient has an allergy\n",
    "# Use different notebook to load the model and return a prediction\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "214af1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "\n",
    "# Import both datasets, change to local path when running\n",
    "patients = pd.read_excel(r\"C:\\Users\\ncros\\OneDrive\\Desktop\\492\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level2_AI_Patient Traits\")\n",
    "\n",
    "allergies = pd.read_excel(r\"C:\\Users\\ncros\\OneDrive\\Desktop\\492\\Allergy_SanFrancisco\\PATIENTS_Nov_3_2023_V4_sfm-data.xlsx\", sheet_name=\"Level1_Patient Allergens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b8cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that patient sheet imported correctly\n",
    "# Comment below line before committing\n",
    "# patients['SkinConditions'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d34eed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm allergy sheet imported correctly\n",
    "# Comment line before committing\n",
    "# allergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb333603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge columns by ID if needed\n",
    "patientAllergies = patients.merge(allergies, on = \"SFM Id\")\n",
    "# Comment line before committing\n",
    "# patientAllergies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30c97a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID and location columns from dataframe\n",
    "patientsTrimmed = patients.drop(['SFM Id', 'City', 'State', 'Country'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ecc338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode Gender column\n",
    "patientsTrimmed['Gender'] = pd.Categorical(patientsTrimmed['Gender'].str.strip())\n",
    "gender_onehot = pd.get_dummies(patientsTrimmed['Gender'], prefix = \"Gender\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('Gender', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(gender_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f50d9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode SkinTone column\n",
    "patientsTrimmed['SkinTone'] = pd.Categorical(patientsTrimmed['SkinTone'].str.strip())\n",
    "skintone_onehot = pd.get_dummies(patientsTrimmed['SkinTone'], prefix = \"SkinTone\",\n",
    "                                    prefix_sep = \"-\", dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinTone', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(skintone_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04fc1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode FitzPatrickSkinPhotoType column\n",
    "patientsTrimmed['FitzpatrickSkinPhotoType'] = pd.Categorical(patientsTrimmed['FitzpatrickSkinPhotoType'].str.strip())\n",
    "# Dropping first here since it is a blank variable in the column\n",
    "fitzpatrick_onehot = pd.get_dummies(patientsTrimmed['FitzpatrickSkinPhotoType'], prefix = \"Fitzpatrick\",\n",
    "                                    prefix_sep = \"-\", drop_first = True, dtype = int)\n",
    "patientsTrimmed = patientsTrimmed.drop('FitzpatrickSkinPhotoType', axis = 1)\n",
    "patientsTrimmed = patientsTrimmed.join(fitzpatrick_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4c818e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switching to TextVectorization (Tokenizer is deprecated)\n",
    "from keras.layers import TextVectorization\n",
    "# Replace commas with whitespace\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].str.replace(',', ' ')\n",
    "# Set the max length based on whitespace characters\n",
    "max_len = patientsTrimmed['SkinConditions'].str.count(' ').max()\n",
    "# Create TextVectorization object, separating on whitespace and using the max_len from earlier\n",
    "vectorizer = TextVectorization(split = 'whitespace', output_sequence_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "537f2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt using the column we want to convert\n",
    "vectorizer.adapt(patientsTrimmed['SkinConditions'].values)\n",
    "# Reset the column after converting values to vector and placing in array\n",
    "skinConditions = vectorizer(patientsTrimmed['SkinConditions']).numpy()\n",
    "patientsTrimmed = patientsTrimmed.drop('SkinConditions', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5781a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsArr = patientsTrimmed.values\n",
    "input_data = np.concatenate((patientsArr, skinConditions), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "255b5582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Old code for SkinConditions conversion - leaving in case we need later\\n# Code to preprocess the SkinConditions column, tokenizing should be more recognizable to keras than regular text\\n## Delete if this idea does not work\\nfrom keras.preprocessing.text import Tokenizer\\nfrom keras.preprocessing.sequence import pad_sequences\\n\\n# Flatten entries into actual lists\\npatientsTrimmed[\\'SkinConditions\\'] = patientsTrimmed[\\'SkinConditions\\'].apply(lambda x: \\' \\'.join(x))\\n# Tokenize the characters of the columns\\ntokenizer = Tokenizer()\\ntokenizer.fit_on_texts(patientsTrimmed[\\'SkinConditions\\'])\\n# Create and pad sequences of the tokens\\npatientsTrimmed[\\'SkinConditions\\'] = tokenizer.texts_to_sequences(patientsTrimmed[\\'SkinConditions\\'])\\nmax_length = max(len(seq) for seq in patientsTrimmed[\\'SkinConditions\\'])\\ntestVar = pad_sequences(patientsTrimmed[\\'SkinConditions\\'], maxlen = max_length, padding = \"post\")\\npatientsTrimmed[\\'SkinConditions\\'] = testVar.tolist()\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Old code for SkinConditions conversion - leaving in case we need later\n",
    "# Code to preprocess the SkinConditions column, tokenizing should be more recognizable to keras than regular text\n",
    "## Delete if this idea does not work\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Flatten entries into actual lists\n",
    "patientsTrimmed['SkinConditions'] = patientsTrimmed['SkinConditions'].apply(lambda x: ' '.join(x))\n",
    "# Tokenize the characters of the columns\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(patientsTrimmed['SkinConditions'])\n",
    "# Create and pad sequences of the tokens\n",
    "patientsTrimmed['SkinConditions'] = tokenizer.texts_to_sequences(patientsTrimmed['SkinConditions'])\n",
    "max_length = max(len(seq) for seq in patientsTrimmed['SkinConditions'])\n",
    "testVar = pad_sequences(patientsTrimmed['SkinConditions'], maxlen = max_length, padding = \"post\")\n",
    "patientsTrimmed['SkinConditions'] = testVar.tolist()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a785a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID column for preprocessing - ID should have no effect on prediction\n",
    "allergiesNoId = allergies.drop('SFM Id', axis = 1)\n",
    "# Remove all non-digit characters, then replace empty cells with NaN\n",
    "allergiesNoId = allergiesNoId.replace(r'\\D+', '', regex = True).replace('', np.nan)\n",
    "# Set all NaN cells to 0\n",
    "allergiesNoId = allergiesNoId.fillna(0)\n",
    "# Convert entire dataframe to integer\n",
    "allergiesNoId = allergiesNoId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f83d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNoId['AllergiesList'] = allergiesNoId.astype(str).apply(' '.join, axis=1)\n",
    "allergiesNoId['AllergiesList'] = allergiesNoId['AllergiesList'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93a60a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# Create MultiLabelBinarizer object\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "allergiesArr = np.array(allergiesNoId['AllergiesList'])\n",
    "# Multi-hot encode data\n",
    "allergiesArray = mlb.fit_transform(allergiesArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9568019",
   "metadata": {},
   "outputs": [],
   "source": [
    "allergiesNew = mlb.inverse_transform(allergiesArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac504b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         int32\n",
       "100612    int32\n",
       "100613    int32\n",
       "100702    int32\n",
       "100857    int32\n",
       "          ...  \n",
       "9804      int32\n",
       "98288     int32\n",
       "99100     int32\n",
       "9926      int32\n",
       "99356     int32\n",
       "Length: 731, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergiesDF = pd.DataFrame(mlb.transform(allergiesArr), columns = mlb.classes_)\n",
    "allergiesDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b032100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold #:  1\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 4s 15ms/step - loss: 0.0543 - val_loss: 0.0383\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0306 - val_loss: 0.0258\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0249 - val_loss: 0.0221\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0181 - val_loss: 0.0159\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0163 - val_loss: 0.0153\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0160 - val_loss: 0.0154\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0146 - val_loss: 0.0137\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0132 - val_loss: 0.0142\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0184 - val_loss: 0.0163\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0170 - val_loss: 0.0177\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0194 - val_loss: 0.0211\n",
      "62/62 [==============================] - 0s 4ms/step\n",
      "X values for test:  [1950    1    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "    0    0    0    3    5    2    6    4    8    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '124', '144962', '1462', '1590', '1600', '1607', '1827', '188', '5468', '5986', '9300')\n",
      "Predicted values as list:  ('0', '10541', '11661', '119', '11996', '124', '124737', '12522', '130118', '133629', '134800', '137795', '13891', '144962', '1496', '1530', '1586', '1588', '1589', '1590', '1592', '1594', '1595', '1597', '1598', '1600', '1601', '1602', '1604', '1605', '1607', '1609', '1610', '1613', '1615', '1632', '1826', '183', '184', '1964', '1995', '1997', '201', '2015', '2023', '2042', '2044', '2047', '21339', '215', '227', '2293', '240', '24061', '257', '263', '26803', '28559', '29231', '30442', '33172', '33173', '35361', '37026', '3793', '38080', '3962', '41609', '41728', '4185', '44465', '4550', '459', '4617', '4929', '5272', '5345', '5405', '5468', '5825', '5986', '6020', '6096', '615', '61707', '61708', '634', '6416', '6509', '68258', '6841', '69227', '7086', '7454', '75912', '7651', '7737', '799', '800', '8140', '83935', '9274', '9298', '9308', '9310', '9314', '9315', '9338', '9339', '9341', '9342', '9344', '9351', '9400', '95426', '95438')\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Area under the curve:  0.3488372\n",
      "Precision:  0.049804077\n",
      "Recall:  0.762956\n",
      "Precision/Recall avg:  0.24227878\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  2\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 4s 15ms/step - loss: 0.0504 - val_loss: 0.0344\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0324 - val_loss: 0.0381\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0264 - val_loss: 0.0298\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0234 - val_loss: 0.0275\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0230 - val_loss: 0.0228\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0214 - val_loss: 0.0181\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0172 - val_loss: 0.0199\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0212 - val_loss: 0.0204\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.0192 - val_loss: 0.0176\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.0172 - val_loss: 0.0162\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 3s 15ms/step - loss: 0.0152 - val_loss: 0.0148\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0129 - val_loss: 0.0124\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0130 - val_loss: 0.0140\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0126 - val_loss: 0.0127\n",
      "62/62 [==============================] - 1s 8ms/step\n",
      "X values for test:  [2000    0    1    0    0    0    1    0    0    0    0    0    0    0\n",
      "    0    0    0   14    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '15438', '18419', '5443')\n",
      "Predicted values as list:  ('0', '103637', '105017', '10541', '1149', '1153', '119', '121146', '124', '124737', '12522', '13018', '131996', '132762', '136704', '13891', '144962', '148092', '1487', '1496', '1586', '1588', '1589', '1590', '1592', '1594', '1595', '1596', '1598', '1600', '1601', '1602', '1604', '1605', '1607', '1609', '1610', '1613', '1615', '1802', '1827', '1903', '1995', '1996', '1997', '2008', '201', '2023', '204', '2042', '205', '210', '215', '2269', '227', '2292', '240', '24061', '24816', '2536', '26803', '2761', '28559', '30442', '33172', '33173', '35361', '3793', '3799', '38080', '41609', '44465', '4550', '459', '4617', '4668', '4701', '47438', '4928', '4929', '51508', '5236', '5272', '5405', '5986', '6011', '6020', '607', '6096', '614', '61707', '62', '634', '6509', '68258', '68271', '6841', '69227', '7086', '73771', '7454', '800', '8139', '8376', '8386', '83935', '8469', '9116', '9275', '9276', '9277', '9308', '9310', '9312', '9314', '9315', '9338', '9341', '9342', '9348', '9466', '95426', '95438', '96771')\n",
      "[1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the curve:  0.3508892\n",
      "Precision:  0.048765883\n",
      "Recall:  0.8037728\n",
      "Precision/Recall avg:  0.24295928\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1977    0]\n",
      "  [   3    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]]\n",
      "Running fold #:  3\n",
      "Epoch 1/20\n",
      "198/198 [==============================] - 7s 22ms/step - loss: 0.0538 - val_loss: 0.0326\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0299 - val_loss: 0.0264\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0259 - val_loss: 0.0269\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0231 - val_loss: 0.0186\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0197 - val_loss: 0.0190\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0167 - val_loss: 0.0147\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0141 - val_loss: 0.0135\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0166 - val_loss: 0.0173\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0132 - val_loss: 0.0150\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0131 - val_loss: 0.0106\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.0139 - val_loss: 0.0153\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 16/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 17/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0133 - val_loss: 0.0135\n",
      "Epoch 18/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 19/20\n",
      "198/198 [==============================] - 4s 21ms/step - loss: 0.0156 - val_loss: 0.0143\n",
      "Epoch 20/20\n",
      "198/198 [==============================] - 4s 20ms/step - loss: 0.0207 - val_loss: 0.0212\n",
      "62/62 [==============================] - 1s 6ms/step\n",
      "X values for test:  [1946    1    0    0    0    0    0    0    0    1    0    0    0    0\n",
      "    0    0    0    3    7    2    6    4    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "Actual y values as list:  ('0', '1600', '1613', '201', '2023', '2787', '9315', '9456')\n",
      "Predicted values as list:  ('0', '103637', '104630', '105017', '10541', '10546', '1153', '11790', '119', '124', '12522', '130118', '131996', '132762', '134800', '136', '140625', '144962', '1453', '148092', '1588', '1589', '1590', '1592', '1594', '1596', '1597', '1598', '1600', '1601', '1602', '1605', '1607', '1609', '1610', '1826', '1893', '190', '192', '1988', '1990', '1995', '1997', '201', '2023', '203', '204', '2042', '205', '21340', '227', '24061', '2536', '263', '26803', '28559', '33172', '33173', '3766', '3793', '3799', '38080', '3962', '41609', '44465', '4550', '459', '4619', '4824', '4928', '4929', '5236', '5272', '5405', '5467', '5560', '5825', '5926', '598', '5986', '607', '6096', '614', '61707', '62', '6509', '68271', '6841', '69227', '7086', '73771', '7454', '7669', '7737', '799', '80', '800', '83935', '8469', '9275', '9277', '9300', '9308', '9310', '9314', '9315', '9338', '9341', '9344', '9351', '9456', '9466', '95438', '96771')\n",
      "[1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "Area under the curve:  0.3248974\n",
      "Precision:  0.051590465\n",
      "Recall:  0.79061717\n",
      "Precision/Recall avg:  0.24801451\n",
      "[[[   0    0]\n",
      "  [   0 1980]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1979    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[1978    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1980    0]\n",
      "  [   0    0]]]\n",
      "Running fold #:  4\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "from keras.layers import Average\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7869)\n",
    "\n",
    "#weight_array = compute_class_weight(class_weight = 'balanced', \n",
    "                                    #classes = np.unique(np.argmax(allergiesArray, axis=1)), \n",
    "                                    #y = np.argmax(allergiesArray, axis=1))\n",
    "#print(weight_array)\n",
    "#weight_dict = dict(zip(np.unique(np.argmax(allergiesArray, axis=1)), weight_array))\n",
    "#print(weight_dict)\n",
    "\n",
    "fold_count = 1\n",
    "# Train the model for each split\n",
    "# Define the model inside the for loop\n",
    "for train, test in cv.split(input_data,allergiesArray):\n",
    "\n",
    "    n_classes = 731\n",
    "\n",
    "    # Input layer\n",
    "    input_shape = (40,)\n",
    "    inputs = keras.Input(input_shape)\n",
    "\n",
    "    # Hidden layers\n",
    "    x = Dense(128, activation='sigmoid')(inputs)\n",
    "    x = Dense(512, activation = 'sigmoid')(x)\n",
    "    x = Dense(2048, activation = 'sigmoid')(x)\n",
    "\n",
    "    # Output layer - use multilabel classification\n",
    "    predictions = Dense(n_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs = inputs, outputs = predictions)\n",
    "    model.compile(loss=keras.losses.BinaryFocalCrossentropy(apply_class_balancing=True, alpha = 0.05, gamma = 12), optimizer=keras.optimizers.Adam(learning_rate=0.1))\n",
    "    \n",
    "    print(\"Running fold #: \", fold_count)\n",
    "\n",
    "    fold_train_x =input_data[train]\n",
    "    \n",
    "    history = model.fit(\n",
    "    fold_train_x, allergiesArray[train],\n",
    "    epochs = 20, \n",
    "    verbose = 1, \n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "    fold_test_x = input_data[test]\n",
    "    y_true = allergiesArray[test]\n",
    "    \n",
    "    # pred_y = model.predict_classes(fold_test_x, verbose = 1)\n",
    "    probs = model.predict(fold_test_x, verbose = 1)\n",
    "    \n",
    "\n",
    "    # AUC (Area Under Curve): how well the model can classify into the classes (high numbers better)\n",
    "    auc = keras.metrics.AUC(multi_label = True, num_labels = 731, from_logits = False)\n",
    "    # Precision: how well model predicts target class (high numbers better)\\\n",
    "    prec = keras.metrics.Precision()\n",
    "    # Recall: how many objects model can find (high numbers better)\n",
    "    rec = keras.metrics.Recall()\n",
    "    # F1Score: mean between precision and recall\n",
    "    f1 = keras.metrics.F1Score(average = 'weighted')\n",
    "\n",
    "    threshold = 0.35\n",
    "    probs = (probs > threshold).astype(int)\n",
    "    # print(\"Predicted y values: \", pred_y[0])\n",
    "    print(\"X values for test: \", fold_test_x[0])\n",
    "    yList = mlb.inverse_transform(y_true)\n",
    "    print(\"Actual y values as list: \", yList[0])\n",
    "    probsList = mlb.inverse_transform(probs)\n",
    "    print(\"Predicted values as list: \", probsList[0])\n",
    "    print(probs[0])\n",
    "    \n",
    "    auc.update_state(y_true, probs)\n",
    "    print(\"Area under the curve: \", auc.result().numpy())\n",
    "    prec.update_state(y_true, probs)\n",
    "    print(\"Precision: \",prec.result().numpy())\n",
    "    rec.update_state(y_true, probs)\n",
    "    print(\"Recall: \",rec.result().numpy())\n",
    "    f1.update_state(y_true, probs)\n",
    "    print(\"Precision/Recall avg: \",f1.result().numpy())\n",
    "    \n",
    "    matrix = multilabel_confusion_matrix(y_true, probs)\n",
    "    print(matrix)\n",
    "    \n",
    "    # print(\"Accuracy score sklearn: \", accuracy_score(allergiesArray[test], probs))\n",
    "    accuracy = (allergiesArray[test] == probs).all(axis=(0,1)).mean()\n",
    "    # print(\"Accuracy score equation: \", accuracy)\n",
    "\n",
    "    fold_count = fold_count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save Keras model as separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c3c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
